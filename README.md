
# EVO NIA: Evolutionary Neural Intelligence Algorithm

## Research Motivation

This project explores the integration of evolutionary computation with neural intelligence to improve optimization and classification tasks. By leveraging evolutionary strategies, the algorithm adapts dynamically to data distributions, aiming to outperform standard clustering and classification approaches. This research is motivated by the growing need for adaptive, explainable, and efficient AI systems in data-driven domains.

## Objectives

* Implement an evolutionary optimization framework combined with neural methods.
* Apply the model to real-world datasets and evaluate performance.
* Compare results with baseline clustering/classification algorithms.
* Analyze adaptability, accuracy, and scalability of the approach.

## Methodology

* **Languages & Tools**: Python, Jupyter Notebook
* **Libraries**: NumPy, Pandas, Matplotlib, Scikit-learn, (add TensorFlow/PyTorch if used)
* **Techniques**: Evolutionary Algorithms, Neural Intelligence, Optimization Strategies
* **Workflow**:

  1. Data preprocessing
  2. Algorithm implementation
  3. Training & evaluation
  4. Visualization of results

## Results
.
* Demonstrated improved clustering efficiency compared to K-Means baseline.
* Observed reduced training convergence time using evolutionary strategies.
* Key plots and figures are included in the notebook for visualization.

## Applications

* Research in evolutionary computation and artificial intelligence.
* Applications in optimization problems, classification, and clustering.
* Potential use in bioinformatics, recommendation systems, and adaptive decision-making.

## How to Run

```bash
# Clone the repository
git clone https://github.com/your-username/evo-nia.git
cd evo-nia

# Install dependencies
pip install -r requirements.txt

# Open the notebook
jupyter notebook "EVO NIA (2124,2145).ipynb"
```

## Future Work

* Test on larger and more complex datasets.
* Explore integration with deep learning frameworks (TensorFlow/PyTorch).
* Publish results in academic venues for further peer review.
* Extend evolutionary framework for reinforcement learning tasks.

## References

1. An, Y., Zhang, C., Shao, J., Yan, Y., & Sun, B. (2025). *An Efficient Evolutionary Neural Architecture Search Algorithm Without Training.* Biomimetics. [Link](https://www.mdpi.com/2313-7673/10/7/421)

2. Booysen, R., & Bosman, A. S. (2024). *Multi-objective Evolutionary Neural Architecture Search for Recurrent Neural Networks.* Neural Processing Letters. [Link](https://link.springer.com/article/10.1007/s11063-024-11659-0)

3. Jian, Z., Wenran, H., Ying, Z., & Shufan, J. (2023). *EENAS: An Efficient Evolutionary Algorithm for Neural Architecture Search.* Proceedings of the 14th Asian Conference on Machine Learning (ACML), PMLR. [Link](https://proceedings.mlr.press/v189/jian23a.html)

4. Sun, Y., Xue, B., Zhang, M., & Yen, G. G. (2022). *EvoDCNN: An Evolutionary Deep Convolutional Neural Network for Image Classification.* Neurocomputing. [Link](https://dlnext.acm.org/doi/10.1016/j.neucom.2022.02.003)

5. Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W. M., Donahue, J., Razavi, A., ... & Kavukcuoglu, K. (2018). *Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks.* NeurIPS. [Link](https://papers.nips.cc/paper/7844-evolutionary-stochastic-gradient-descent-for-optimization-of-deep-neural-networks)


## About Me

I am Yukta, passionate about AI research, optimization algorithms, and data science applications.

* GitHub: [https://github.com/yukta-2203]

